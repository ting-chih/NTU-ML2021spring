## YT  
  * https://www.youtube.com/watch?v=rWF9sg5w6Zk  

## slide  
  * https://speech.ee.ntu.edu.tw/~hylee/ml/ml2021-course-data/life_v2.pdf  

## Life-long learning  
## LLL in real-world applications  
 * The network has enough capacity to learn both tasks.  
 * old tasks(labelled data) -> Model -> online -> Feedback -> New tasks -> Model  

## Catastrophic forgetting(Multi-task training can be considered as the upper bound of LLL)  
 * Computation issue: Using all the data for training  
 * Storage issue: Always keep the data  

## Evaluation - LLL  
 * https://arxiv.org/pdf/1904.07734.pdf  
 * Accuracy, Backward transfer, Forward transfer  

## Research directions - Catastrophic forgetting  
## Selective Synaptic Plasticity - Regularization based Approach  
