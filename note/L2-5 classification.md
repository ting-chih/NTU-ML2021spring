slide: https://speech.ee.ntu.edu.tw/~hylee/ml/ml2021-course-data/classification_v2.pdf  

## Class as one-hot vector  

  ![Image of Yaktocat](https://github.com/ting-chih/NTU-ML2021spring/blob/main/image/classification.png)

## In Classification, y is not a value, is a vector.  
  
   ![Image of Yaktocat](https://github.com/ting-chih/NTU-ML2021spring/blob/main/image/RVC.png)

## What is Soft-Max  

![Image of Yaktocat](https://github.com/ting-chih/NTU-ML2021spring/blob/main/image/softmax.png)

## How about binary classification? Ans: Sigmoid

## Loss of Classification -> Cross entropy  

![Image of Yaktocat](https://github.com/ting-chih/NTU-ML2021spring/blob/main/image/loss%20of%20classification.png)

## In pytorch, cross-entropy function has soft-max network.  
## Using cross-entropy, you do not need to add soft-max in your network.  
