## YT  
  * https://www.youtube.com/watch?v=gh0hewYkjgo  

## Self-supervised Learning  
![Image of Yaktocat](https://github.com/ting-chih/NTU-ML2021spring/blob/main/image/self-supervised%20learning.png)  

## BERT  
![Image of Yaktocat](https://github.com/ting-chih/NTU-ML2021spring/blob/main/image/BERT.png)  
 * Masked token prediction  
 * Next sentence prediction  
 * Downstream Tasks:  
   * The tasks we care  
   * We have a little bit labeled data  

## Self-supervised Learning (pre-train) -> BERT (Fine-tine) -> Model for Task1, Task2, Task3  

## Case 1: Sentiment analysis  
![Image of Yaktocat](https://github.com/ting-chih/NTU-ML2021spring/blob/main/image/case1.png)  

## Case 2: POS tagging  
![Image of Yaktocat](https://github.com/ting-chih/NTU-ML2021spring/blob/main/image/case2.png)  

## Case 3: Natural Language Inference(NLI)  
 * input: 2 sequences  
 * output: a class  
 * Example:  
   * (Premise + Hypothesis) -> Model -> (contradiction, entailment, neutral)  
   * Premise: a person on a horse jumps over a broken down airplane.  
   * Hypothesis: a person is at a diner.  
![Image of Yaktocat](https://github.com/ting-chih/NTU-ML2021spring/blob/main/image/case3.png)  
