## YT  
  * https://www.youtube.com/watch?v=3oHlf8-J3Nc&feature=youtu.be  
## Slide  
  * https://speech.ee.ntu.edu.tw/~hylee/ml/ml2021-course-data/auto_v8.pdf  

## Auto-encoder like Self-supervised learning  
  * learned by tasks not requiring label data  

## Auto-encoder  
  * input: a image  
  * output: a image(as close as possible with input) (reconstruction)  
  * input -> NN Encoder -> vector -> NN Decoder -> output  
  * Auto-encoder mission: translate input(high dimension) to vector(low dimension) => Dimension reduction  

## Why auto-encoder -> Find pattern, and then compress  
  * Finding the different pattern in the image, auto-encoder uses low-dim vector to record the high-dim image.  

## De-noising Auto-encoder and BERT  
![Image of Yaktocat]()  
![Image of Yaktocat]()  
